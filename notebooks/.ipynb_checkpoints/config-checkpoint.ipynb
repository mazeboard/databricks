{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae904ec-cfbc-4c9b-aa49-909cd00ec5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from databricks.sdk.runtime import *\n",
    "\n",
    "def initialize_context():\n",
    "    dbutils.widgets.text('tenantId', '')\n",
    "    dbutils.widgets.text('workspaceId', '')\n",
    "    dbutils.widgets.text('dataProjectId', '')\n",
    "    dbutils.widgets.text('importId', '')\n",
    "    dbutils.widgets.text('jobId', '')\n",
    "\n",
    "    tenant_id = dbutils.widgets.get('tenantId')\n",
    "    workspace_id = dbutils.widgets.get('workspaceId')\n",
    "    project_id = dbutils.widgets.get('dataProjectId')\n",
    "    import_id = dbutils.widgets.get('importId')\n",
    "    job_id = dbutils.widgets.get('jobId')\n",
    "\n",
    "\n",
    "    table_prefix = f\"tenant_{tenant_id}.workspace_{workspace_id}\"\n",
    "\n",
    "    return {\n",
    "        \"tenant_id\": tenant_id,\n",
    "        \"workspace_id\": workspace_id,\n",
    "        \"table_prefix\": table_prefix,\n",
    "        \"project_id\": project_id,\n",
    "        \"import_id\": import_id,\n",
    "        \"job_id\": job_id\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2237bffc-f85c-437f-b55a-757b668c9d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from databricks.sdk.runtime import *\n",
    "\n",
    "driver = \"org.postgresql.Driver\"\n",
    "database_host = dbutils.secrets.get(scope=\"arlq-vault\", key=\"arlq-pg-host-secret\")\n",
    "database_port = \"5432\"\n",
    "user = dbutils.secrets.get(scope=\"arlq-vault\", key=\"arlq-pg-username-secret\")\n",
    "password = dbutils.secrets.get(scope=\"arlq-vault\", key=\"arlq-pg-pwd-secret\")\n",
    "\n",
    "def connection(database_name):\n",
    "    return psycopg2.connect(\n",
    "        host=database_host,\n",
    "        database=database_name,\n",
    "        user=user,\n",
    "        password=password,\n",
    "        sslmode=\"require\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb7f976-6893-4d9e-9f3c-67c859c3dbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "from databricks.sdk.runtime import *\n",
    "\n",
    "#from databases import connection\n",
    "\n",
    "class DataProject:\n",
    "\n",
    "    def __init__(self, id):\n",
    "        self.id = id\n",
    "\n",
    "    def connection(self):\n",
    "        return connection(dbutils.secrets.get(scope=\"arlq-vault\", key=\"arlq-pg-data-projects-db-secret\"))\n",
    "    \n",
    "    def getImport(self, importId):\n",
    "        sql = f\"\"\"\n",
    "            SELECT *\n",
    "            FROM \"data-project-attachments\"\n",
    "            WHERE id = %s\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with self.connection() as conn:\n",
    "                with conn.cursor(cursor_factory=psycopg2.extras.DictCursor) as cursor:\n",
    "                    cursor.execute(sql, (importId,))\n",
    "                    attachment = cursor.fetchone()\n",
    "\n",
    "                    def extract_params():\n",
    "                        try:\n",
    "                            return json.loads(attachment['params'])\n",
    "                        except:\n",
    "                            return attachment['params']\n",
    "\n",
    "                    return {\n",
    "                        \"importId\": attachment['external_id'],\n",
    "                        \"params\": extract_params()\n",
    "                    }\n",
    "        except (Exception, psycopg2.DatabaseError) as error:\n",
    "            print(error)\n",
    "\n",
    "    def getConfiguration(self):\n",
    "        sql = f\"\"\"\n",
    "            SELECT *\n",
    "            FROM \"data-project-configurations\"\n",
    "            JOIN (\n",
    "                SELECT\n",
    "                    data_project_configuration_id,\n",
    "                    JSON_AGG(\n",
    "                        ROW_TO_JSON(\"data-project-configuration-parameters\")\n",
    "                    )\n",
    "                FROM \"data-project-configuration-parameters\"\n",
    "                GROUP BY data_project_configuration_id\n",
    "            ) AS parameters\n",
    "                ON parameters.data_project_configuration_id = \"data-project-configurations\".id\n",
    "            WHERE \"data-project-configurations\".id = %s\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with self.connection() as conn:\n",
    "                with conn.cursor(cursor_factory=psycopg2.extras.DictCursor) as cursor:\n",
    "                    cursor.execute(sql, (self.id,))\n",
    "                    configuration = cursor.fetchone()\n",
    "                    \n",
    "                    paramters_by_name = itertools.groupby(\n",
    "                        sorted(configuration['json_agg'], key=lambda p: p['parameter']),\n",
    "                        lambda p: p['parameter']\n",
    "                    )\n",
    "\n",
    "                    def format_parameter(parameter):\n",
    "                        values = {}\n",
    "                        \n",
    "                        for value in parameter:\n",
    "                            if value['key'] is None and value['index'] is None:\n",
    "                                try:\n",
    "                                    values['value'] = json.loads(value['value'])\n",
    "                                except:\n",
    "                                    values['value'] = value['value']\n",
    "\n",
    "                        return values\n",
    "\n",
    "                    return dict([(p, format_parameter(v)) for p, v in paramters_by_name])\n",
    "        except (Exception, psycopg2.DatabaseError) as error:\n",
    "            print(error)\n",
    "\n",
    "    def export_content_topics(self, content_topics, import_id):\n",
    "        sql = f\"\"\"\n",
    "            INSERT INTO \"data-project-content-topics\"(\n",
    "                id, data_project_id, import_id,\n",
    "                content_topic, description, medium_description, small_description, topic_size, total_size\n",
    "            )\n",
    "            VALUES(%s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            with self.connection() as conn:\n",
    "                with conn.cursor() as cursor:\n",
    "                    cursor.execute('DELETE FROM \"data-project-content-topics\" WHERE data_project_id=%s AND import_id=%s', (self.id, import_id))\n",
    "                    for row in content_topics:\n",
    "                        cursor.execute(sql, (row[\"id\"], row[\"project_id\"], row[\"content_group\"], row[\"content_topic\"], row[\"description\"], row[\"medium_description\"], row[\"small_description\"], row[\"topic_size\"], row[\"total_size\"]))\n",
    "                    conn.commit()\n",
    "        except (Exception, psycopg2.DatabaseError) as error:\n",
    "            print(error)\n",
    "\n",
    "    def export_content_topics_v2(self, content_topics, import_id):\n",
    "        sql = f\"\"\"\n",
    "            INSERT INTO \"data-project-content-topics\"(\n",
    "                id, data_project_id, import_id,\n",
    "                content_topic, content_topic_clusters, content_topic_ancestor,\n",
    "                description, topic_size, total_size\n",
    "            )\n",
    "            VALUES(%s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            with self.connection() as conn:\n",
    "                with conn.cursor() as cursor:\n",
    "                    cursor.execute('DELETE FROM \"data-project-content-topics\" WHERE data_project_id=%s AND import_id=%s', (self.id, import_id))\n",
    "                    for row in content_topics:\n",
    "                        cursor.execute(sql, (\n",
    "                            row[\"id\"], row[\"project_id\"], row[\"content_group\"],\n",
    "                            row[\"content_topic\"], row[\"content_topic_clusters\"], row[\"content_topic_ancestor\"],\n",
    "                            row[\"description\"], row[\"topic_size\"], row[\"total_size\"]))\n",
    "                    conn.commit()\n",
    "        except (Exception, psycopg2.DatabaseError) as error:\n",
    "            print(error)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cb0cea-8182-48b8-ab4f-f125be7375cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from databricks.sdk.runtime import *\n",
    "\n",
    "#from databases import connection\n",
    "\n",
    "class Workspace:\n",
    "\n",
    "    def __init__(self, id):\n",
    "        self.id = id\n",
    "\n",
    "    def connection(self):\n",
    "        return connection(dbutils.secrets.get(scope=\"arlq-vault\", key=\"arlq-pg-workspaces-db-secret\"))\n",
    "\n",
    "    def initProgress(self, jobId, total):\n",
    "        sql = \"\"\"\n",
    "            UPDATE \"workspace-jobs\"\n",
    "            SET total_steps=%s, completed_steps=0\n",
    "            WHERE id=%s\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with self.connection() as conn:\n",
    "                with conn.cursor() as cursor:\n",
    "                    cursor.execute(sql, (total, jobId,))\n",
    "                    conn.commit()\n",
    "        except (Exception, psycopg2.DatabaseError) as error:\n",
    "            print(error)\n",
    "\n",
    "    def progress(self, jobId):\n",
    "        sql = \"\"\"\n",
    "            UPDATE \"workspace-jobs\"\n",
    "            SET completed_steps = completed_steps + 1\n",
    "            WHERE id=%s\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            with self.connection() as conn:\n",
    "                with conn.cursor() as cursor: \n",
    "                    cursor.execute(sql, (jobId,))\n",
    "                    conn.commit()\n",
    "        except (Exception, psycopg2.DatabaseError) as error:\n",
    "            print(error) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
